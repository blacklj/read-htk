# HInit
### 功能说明
为了定义一个hmm，我们首先可以通过文本编辑器手工创建一个初始的hmm文件，文件中应包含状态转移矩阵、均值和方差。其次，HInit工具将hmm模型看作为语音特征矢量的产生器，可以用于初始化hmm参数。
### 处理流程
HInit的处理流程包括：对观察向量均匀分段、参数初始化、viterbi对齐以及参数更新。如下图：
![HInit icon](/Users/liz/workspace/learning/htk/HTKRead/res/HInit_1.png)
### 数据结构
~~~c

~~~
### 函数说明
~~~c
LogFloat ViterbiAlign(int segNum,int segLen,IntVec states,IntVec *mixes)
~~~
该函数采用的viterbi算法与经典的viterbi算法有一点区别的是，hmm模型的起始状态和结束状态是非激发态，因而viterbi路径从nState=2到nState=numStates-1。

viterbi算法描述如下<http://www.52nlp.cn/hmm-learn-best-practices-six-viterbi-algorithm-4>：

1. 维特比算法可以形式化的概括为：对于每一个i，i = 1，... ，n，令：

	![viterbi1](http://www.52nlp.cn/images/6.2.1_a.gif)　　
	
	这一步是通过隐藏状态的初始概率和相应的观察概率之积计算了t=1时刻的局部概率。
	
	对于t=2，...，T和i=1，...，n,令：
	![viterbi2](http://www.52nlp.cn/images/6.2.1_b.gif)
	
	这样就确定了到达下一个状态的最可能路径，并对如何到达下一个状态做了记录。具体来说首先通过考察所有的转移概率与上一步获得的最大的局部概率之积，然后记录下其中最大的一个，同时也包含了上一步触发此概率的状态。
	
	令：
	
	![viterbi3](http://www.52nlp.cn/images/6.2.1_c.gif)
	
	这样就确定了系统完成时(t=T)最可能的隐藏状态。对于t=T-1，...，1，令：
	
	![viterbi4](http://www.52nlp.cn/images/6.2.1_d.gif)
	
	这样就可以按最可能的状态路径在整个网格回溯。回溯完成时，对于观察序列来说，序列i1 ... iT就是生成此观察序列的最可能的隐藏状态序列。
	
2. 计算单独的delta's和phi's

维特比算法中的局部概率delta's的计算与前向算法中的局部概率alpha's的很相似。下面这幅图表显示了delta's和phi's的计算细节:

![viterbi5](http://www.52nlp.cn/images/example.viterbi.gif)

从图中可以看出，每向前走一步，viterbi算法都会遍历前一步所有状态，寻找到达当前状态概率最大的那条路径。

3. 总结

对于一个特定的隐马尔科夫模型，维特比算法被用来寻找生成一个观察序列的最可能的隐藏状态序列。我们利用概率的时间不变性，通过避免计算网格中每一条路径的概率来降低问题的复杂度。维特比算法对于每一个状态(t>1)都保存了一个反向指针(phi)，并在每一个状态中存储了一个局部概率(delta)。局部概率delta是由反向指针指示的路径到达某个状态的概率。

当t=T时，维特比算法所到达的这些终止状态的局部概率delta's是按照最优（最可能）的路径到达该状态的概率。因此，选择其中最大的一个，并回溯找出所隐藏的状态路径，就是这个问题的最好答案。

关于维特比算法，需要着重强调的一点是它不是简单的对于某个给定的时间点选择最可能的隐藏状态，而是基于全局序列做决策——因此，如果在观察序列中有一个“非寻常”的事件发生，对于维特比算法的结果也影响不大。

这在语音处理中是特别有价值的，譬如当某个单词发音的一个中间音素出现失真或丢失的情况时，该单词也可以被识别出来。
　　　　　